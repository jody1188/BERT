{
    "tokenizer_dir" : "./file/tokenizer",
    "checkpoint_dir" : "./file/model/",
    "vocab_size" : 30522,
    "seq_len" : 512,
    "min_freq" : 2,
    "valid_ratio" : 0.2,
    "batch_size" : 32,
    "num_workers" : 1,
    "emb_dim" : 768,
    "ff_dim" : 3072,
    "n_layers" : 12,
    "n_heads" : 12,
    "dropout_prob" : 0.1,
    "n_classes" : 3,
    "learning_rate" : 2e-5,
    "adam_beta1" : 0.9,
    "adam_beta2" : 0.999,
    "weight_decay" : 0.01,
    "warmup_steps" : 10000,
    "log_freq" : 10,
    "with_cuda" : true,
    "cuda_devices" : null,
    "steps" : 345,
    "epochs" : 3
}